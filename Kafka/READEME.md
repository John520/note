# 如何实现事务消息?

## kafka 事务消息

kafka 有事务协调者，也是broker 的一部分。

kafka 向协调者发送开启事务，然后向各个topic 发送消息，最后提交事务。提交事务时，协调者会分两阶段提交，一个是记录到_transaction_state topic 下记录事务的状态，第二阶段到各个topic 下执行消息提交。消费端对于没提交的消息进行过滤（也即依赖消费端的版本大于等于0.11版本，同时需要将隔离级别设置成读已提交）。 

## rocket mq 事务消息

Rocket mq 会将消息先写入一个`RMQ_SYS_TRANS_HALF_TOPIC` 队列，然后启动定时任务消费这个队列，若用户最后提交了事务，则将消息投递到用户消息中指定的队列，若用户超时没有提交或回滚，则会通过回查接口（producer初始化时注册了会查接口）查询状态。最终的消息状态会记录到`harf op`队列。

`RMQ_SYS_TRANS_HALF_TOPIC`队列的消息是顺序写入，所以当事务回查或者提交是并不会修改prepare 的消息状态，而是继续向前推进offset, 而是由`harf op`队列（我理解应该在内存中是字典的数据接口）来做幂等，对于超时没有提交或者回滚的消息，在回查消息之后还没最终结论，会将消息追加到`RMQ_SYS_TRANS_HALF_TOPIC` 队列，并继续向前推送offset



参考：https://juejin.cn/post/6867040340797292558



# 为什么性能好？

1. 利用partition 并行处理：不同partition 可能位于不同的机器，即便位于相同的机器，也是在不同的文件路径，可以并行处理
2. 顺序写磁盘：数据在相同分区是能保证有序性，且相同partition数据是一直追加的方式
3. 充分利用page cache: 数据只写入操作系统文件缓存，并不需要flush 到磁盘，保证了高性能。至于宕机数据丢失，则是通过replication 来保证，及若每个分区有3个从节点，那么主节点将数据都同步到3个从节点都才返回，3个从节点全部宕机丢失数据的概率太低了
4. 零拷贝： producer-->broker-->consumer 数据流向，linux 2.6之后的sendfile 接口会是的将原本四次上下文切换和四次拷贝变成两次上下文切换两次内存拷贝

5. 批处理pipeline： 累积多条消息一次传输，提高带宽利用率
6. 数据压缩：数据压缩之后在发送给brokerz